---
title: "Twitter Tibbles"
author: "Cassidy Bargell"
date: "3/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rtweet)
library(httpuv)
library(gtrendsR)
library(lubridate)
```

```{r twitter setup}

# Twitter set-up stuff

app_name <- "clb_twitter_app"
api_key <- "qFVEvxpEi0OmgWSmuIgG7RMPx"
api_secret_key <- "4KAvZL1OFZIITkrxY7xou9dAsTurvlvrXcd5edKX7NoVJ1sGyf"
token <- create_token(
  app = "clb_twitter_app",
  consumer_key = api_key,
  consumer_secret = api_secret_key)

path_to_token <- file.path(path.expand("~"), ".twitter_token.rds")
saveRDS(token, path_to_token)
env_var <- paste0("TWITTER_PAT=", path_to_token)
cat(env_var, file = file.path(path.expand("~"), ".Renviron"), 
  fill = TRUE, append = TRUE)

readRenviron("~/.Renviron")
```

```{r scrape twitter concussion}

# Deciding on what columns from search_tweets I really need. I am thinking
# user_id, created_at, screen_name, text, is_quote, is_retweet, retweet_count,
# favorite_count, quote_count, reply_count, and hashtags. Could full_join the
# tibbles from all the sports to save from each set of dates, but then need to
# make a new identifying column for each sport.

rugby_tweets <- search_tweets("rugby AND concussion", n = 1000, include_rts = FALSE) %>%
  select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)

football_tweets <- search_tweets("football AND concussion", n = 1000, include_rts = FALSE) %>%
    select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)

soccer_tweets <- search_tweets("soccer AND concussion", n = 1000, include_rts = FALSE) %>% 
  select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)

hockey_tweets <- search_tweets("hockey AND concussion", n = 1000, include_rts = FALSE) %>% 
  select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)
```


```{r}

# Decided I wanted to save multiple tibbles of data from when I run search_tweet
# because it will re-scrape twitter for only 7 day chunks. Talked with Mitchell
# at study hall and found out how to save different dates twitter_search results
# as a RDS so then can access them later past 7 days out. Figured out how to
# create the RDS documents, so going to create a new repo and save this code
# into that so everytime I run the code chunk it will save to that repo and
# file, but it will be the same code as this.

file.create("rugby_3_5_20.RDS")
saveRDS(rugby_tweets, file = "rugby_3_5_20.RDS")

rugbytweets <- readRDS("rugby_3_5_20.RDS")

file.create("football_3_5_20.RDS")
saveRDS(football_tweets, file = "football_3_5_20.RDS")

footballtweets <- readRDS("football_3_5_20.RDS")

file.create("soccer_3_5_20.RDS")
saveRDS(rugby_tweets, file = "soccer_3_5_20.RDS")

soccertweets <- readRDS("soccer_3_5_20.RDS")

file.create("hockey_3_5_20.RDS")
saveRDS(hockey_tweets, file = "hockey_3_5_20.RDS")

hockeytweets <- readRDS("hockey_3_5_20.RDS")
```


```

